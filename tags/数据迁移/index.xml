<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据迁移 on jiayuan&#39;s Blog</title>
    <link>/tags/%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/</link>
    <description>Recent content in 数据迁移 on jiayuan&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Jun 2024 08:00:00 +0800</lastBuildDate><atom:link href="/tags/%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>在线数据迁移</title>
      <link>/posts/online-data-migrate/</link>
      <pubDate>Tue, 11 Jun 2024 08:00:00 +0800</pubDate>
      
      <guid>/posts/online-data-migrate/</guid>
      <description>在线数据迁移 很多场景都有数据迁移的需求：
单表改分表 增加分表数，分32张表，扩到128张表 原来使用数据库A，后续迁移到数据库B 系统进行重构，新老数据库字段变化 如果允许停机迁移，数据的准确性一致性容易得到保证
但是大部分场景不允许停机迁移，系统中断几分钟，就会带来不少损失。
大部分应用选择不停机迁移，如何保证数据一致性是个问题
双写 打开双写，读老库 迁移存量数据 一致性校验 双写，灰度读新库 双写，全量读新库 下线双写、移除迁移代码 打开双写，目的是新修改数据新老数据库达到一致
迁移存量数据后，新老数据库完全一致
然后维持双写，灰度读新库持续观察，没有问题后读写新库
有问题可以随时切回读写老数据库
实际实施起来，比较复杂
如何双写 先写新库还是先写老库？ update时，如果新数据库没有数据，affect rows不一致，是否需要先从老数据库迁移 老数据库用事务更新多张表，新库是否需要使用事务 双写失败如何处理，接口返回成功还是失败 双insert，失败可能是超时导致，实际已插入，即使超时时增加反查，反查本身仍然可能超时 接口逻辑需多次update，前2个update更新成功，最后一个update新库失败，产生不一致 时序问题 delete与迁移的时序：存量迁移逻辑捞出数据A，准备迁移到新库，此时delete数据A，新老库双delete。数据A执行迁移，新库多数据 异步写新库的时序：如果异步写新库，多个更新的时序会错乱 云控开关时序：期望打开开关的一瞬间，所有实例都感知到变化。但是实际上还会有已经在处理中的请求。因此，处理存量数据时，一般会选择比打开双写早一点的时间，多处理一些数据 怎么保证数据一致 双写无法保证同时成功，有时间差 数据校验 记录update_time，做增量校验 update时，同时更新行的hash值，校验时可以select sum(hash) where xx（适用于结构不变的迁移） 切换期间也可能会引起不一致 一种可行的方式是切换前停止几秒的写请求 存储自身的数据迁移 双写方案在一致性上并不是很完美，可以先看看存储自身是如何处理的，能够提供参考
MySQL 全量同步 可以使用mysqldump导出，导出时记录binlog位置 增量同步 应用binlog 在线结构变更 MySQL早期版本DDL锁表，对应用影响较大，有pt-osc，gh-ost方案可以选择
pt-osc 使用触发器处理新增的修改 原表的insert，在新表replace into 原表的delete，在新表delete ignore 原本的update，在新表replace into 批量导入存量数据 使用insert ignore，避免已经被触发器插入 insert时需要锁，避免delete引起的时序问题 select读到数据A，请求delete A，触发器在新库空操作，然后insert到新库 实际上pt-osc使用insert ignore select xxx from old_table lock in share mode insert select 时持有锁，不会发生这种时序问题 gh-ost 应用binlog处理新增的修改 insert，转为replace into delete，转为delete update，不变 未导入时，update空操作，后续会将新数据导入 导入存量数据，与pt-osc类似 insert ignore select xxx from old_table lock in share mode Redis Cluster Redis对一致性要求并不高，方案可以作为参考</description>
      <content>&lt;h1 id=&#34;在线数据迁移&#34;&gt;在线数据迁移&lt;/h1&gt;
&lt;p&gt;很多场景都有数据迁移的需求：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单表改分表&lt;/li&gt;
&lt;li&gt;增加分表数，分32张表，扩到128张表&lt;/li&gt;
&lt;li&gt;原来使用数据库A，后续迁移到数据库B&lt;/li&gt;
&lt;li&gt;系统进行重构，新老数据库字段变化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果允许停机迁移，数据的准确性一致性容易得到保证&lt;/p&gt;
&lt;p&gt;但是大部分场景不允许停机迁移，系统中断几分钟，就会带来不少损失。&lt;/p&gt;
&lt;p&gt;大部分应用选择不停机迁移，如何保证数据一致性是个问题&lt;/p&gt;
&lt;h1 id=&#34;双写&#34;&gt;双写&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;打开双写，读老库&lt;/li&gt;
&lt;li&gt;迁移存量数据&lt;/li&gt;
&lt;li&gt;一致性校验&lt;/li&gt;
&lt;li&gt;双写，灰度读新库&lt;/li&gt;
&lt;li&gt;双写，全量读新库&lt;/li&gt;
&lt;li&gt;下线双写、移除迁移代码&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;打开双写，目的是新修改数据新老数据库达到一致&lt;/p&gt;
&lt;p&gt;迁移存量数据后，新老数据库完全一致&lt;/p&gt;
&lt;p&gt;然后维持双写，灰度读新库持续观察，没有问题后读写新库&lt;/p&gt;
&lt;p&gt;有问题可以随时切回读写老数据库&lt;/p&gt;
&lt;p&gt;实际实施起来，比较复杂&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如何双写&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;先写新库还是先写老库？&lt;/li&gt;
&lt;li&gt;update时，如果新数据库没有数据，affect rows不一致，是否需要先从老数据库迁移&lt;/li&gt;
&lt;li&gt;老数据库用事务更新多张表，新库是否需要使用事务&lt;/li&gt;
&lt;li&gt;双写失败如何处理，接口返回成功还是失败
&lt;ul&gt;
&lt;li&gt;双insert，失败可能是超时导致，实际已插入，即使超时时增加反查，反查本身仍然可能超时&lt;/li&gt;
&lt;li&gt;接口逻辑需多次update，前2个update更新成功，最后一个update新库失败，产生不一致&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;时序问题&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;delete与迁移的时序：存量迁移逻辑捞出数据A，准备迁移到新库，此时delete数据A，新老库双delete。数据A执行迁移，新库多数据&lt;/li&gt;
&lt;li&gt;异步写新库的时序：如果异步写新库，多个更新的时序会错乱&lt;/li&gt;
&lt;li&gt;云控开关时序：期望打开开关的一瞬间，所有实例都感知到变化。但是实际上还会有已经在处理中的请求。因此，处理存量数据时，一般会选择比打开双写早一点的时间，多处理一些数据&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;怎么保证数据一致&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;双写无法保证同时成功，有时间差&lt;/li&gt;
&lt;li&gt;数据校验
&lt;ul&gt;
&lt;li&gt;记录update_time，做增量校验&lt;/li&gt;
&lt;li&gt;update时，同时更新行的hash值，校验时可以select sum(hash) where xx（适用于结构不变的迁移）&lt;/li&gt;
&lt;li&gt;切换期间也可能会引起不一致
&lt;ul&gt;
&lt;li&gt;一种可行的方式是切换前停止几秒的写请求&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;存储自身的数据迁移&#34;&gt;存储自身的数据迁移&lt;/h1&gt;
&lt;p&gt;双写方案在一致性上并不是很完美，可以先看看存储自身是如何处理的，能够提供参考&lt;/p&gt;
&lt;h2 id=&#34;mysql&#34;&gt;MySQL&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;全量同步
&lt;ul&gt;
&lt;li&gt;可以使用mysqldump导出，导出时记录binlog位置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;增量同步
&lt;ul&gt;
&lt;li&gt;应用binlog&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;在线结构变更&#34;&gt;在线结构变更&lt;/h3&gt;
&lt;p&gt;MySQL早期版本DDL锁表，对应用影响较大，有pt-osc，gh-ost方案可以选择&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pt-osc
&lt;ul&gt;
&lt;li&gt;使用触发器处理新增的修改
&lt;ul&gt;
&lt;li&gt;原表的insert，在新表replace into&lt;/li&gt;
&lt;li&gt;原表的delete，在新表delete ignore&lt;/li&gt;
&lt;li&gt;原本的update，在新表replace into&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;批量导入存量数据
&lt;ul&gt;
&lt;li&gt;使用insert ignore，避免已经被触发器插入&lt;/li&gt;
&lt;li&gt;insert时需要锁，避免delete引起的时序问题
&lt;ul&gt;
&lt;li&gt;select读到数据A，请求delete A，触发器在新库空操作，然后insert到新库&lt;/li&gt;
&lt;li&gt;实际上pt-osc使用insert ignore select  xxx from old_table lock in share mode
&lt;ul&gt;
&lt;li&gt;insert  select 时持有锁，不会发生这种时序问题&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;gh-ost
&lt;ul&gt;
&lt;li&gt;应用binlog处理新增的修改
&lt;ul&gt;
&lt;li&gt;insert，转为replace into&lt;/li&gt;
&lt;li&gt;delete，转为delete&lt;/li&gt;
&lt;li&gt;update，不变
&lt;ul&gt;
&lt;li&gt;未导入时，update空操作，后续会将新数据导入&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;导入存量数据，与pt-osc类似
&lt;ul&gt;
&lt;li&gt;insert ignore select  xxx from old_table lock in share mode&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;redis-cluster&#34;&gt;Redis Cluster&lt;/h2&gt;
&lt;p&gt;Redis对一致性要求并不高，方案可以作为参考&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;全量同步&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;master导出RDB文件，slave加载&lt;/li&gt;
&lt;li&gt;导出RDB期间的读写记录在缓冲区&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;增量同步&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;维持长连接，命令传播&lt;/li&gt;
&lt;li&gt;使用的是环形缓冲区，速度不匹配会丢数据导致不一致&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;slot迁移&#34;&gt;slot迁移&lt;/h3&gt;
&lt;p&gt;新老节点配合&lt;/p&gt;
&lt;p&gt;从老节点迁移数据到新节点&lt;/p&gt;
&lt;p&gt;请求key时，如果该key已经从老节点迁移到新节点，老节点会返回ASK命令&lt;/p&gt;
&lt;p&gt;客户端请求新节点&lt;/p&gt;
&lt;p&gt;迁移完成后，再次请求原本在老节点的key，会返回MOVE命令，客户端可以更新路由&lt;/p&gt;
&lt;h1 id=&#34;数据一致性&#34;&gt;数据一致性&lt;/h1&gt;
&lt;p&gt;一般情况下，双写失败的概率很小，做了数据校验后进行切换，数据不一致概率很低，迁移后还可以再次校验&lt;/p&gt;
&lt;p&gt;但双写无法保证新老存储的事务性，总归是有不一致的概率&lt;/p&gt;
&lt;p&gt;下面讨论两种数据一致性高且比较通用的方案&lt;/p&gt;
&lt;h2 id=&#34;方案一全量同步增量迁移&#34;&gt;方案一：全量同步+增量迁移&lt;/h2&gt;
&lt;p&gt;导出快照，并且记录导出快照时位点，同步存量数据&lt;/p&gt;
&lt;p&gt;利用binlog追增量数据，主从差异降为0或者很小时，禁止主库写入，然后进行切换&lt;/p&gt;
&lt;p&gt;停写可以保证数据一致性，由于大部分都有分库分表，停写只会影响一部分用户&lt;/p&gt;
&lt;p&gt;注意在切换后，避免遗留/新增的请求仍然访问老库&lt;/p&gt;
&lt;h2 id=&#34;方案二细粒度迁移写操作与迁移互斥&#34;&gt;方案二：细粒度迁移，写操作与迁移互斥&lt;/h2&gt;
&lt;p&gt;方案一利用binlog有序，导入全量存量数后追增量数据&lt;/p&gt;
&lt;p&gt;还可以分uid迁移，可以理解成对uid的操作加分布式读写锁&lt;/p&gt;
&lt;p&gt;写操作与迁移操作竞争同一把分布式锁&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;用户在线的读写请求&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读时判断路由，读新库还是老库 (已经切到新库，读了老库不算问题)&lt;/li&gt;
&lt;li&gt;写时加锁，与用户其余写请求、离线迁移互斥&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;worker离线的迁移请求&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分uid迁移，控制速率&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;更具体一点的方案参考：&lt;/p&gt;
&lt;p&gt;新建一张迁移状态表，字段 id,uid,status,ctime,mtime,finish等&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;用户读请求，读迁移状态表，如果finish=1,读新库，否则读老库&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用户写请求，先判断是否迁移完成，可以使用缓存等策略加速&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;状态为待迁移时，更新状态占用锁，update set status = &amp;lsquo;迁移中&amp;rsquo; where status  = &amp;lsquo;待迁移&amp;rsquo; and uid = xxx，然后迁移数据到新库，迁移失败释放锁，下次迁移时删除新库数据；迁移成功后更新status = &amp;lsquo;迁移成功&amp;rsquo;，更新失败释放锁，返回处理失败&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;与分布式锁类似，异常情况下可能会无法释放锁。可以增加一些逻辑，添加heartbeat字段，超时自动剥夺锁，worker定时扫描人工处理等等&lt;/p&gt;
&lt;p&gt;该方案将写与迁移互斥，保证数据一致性&lt;/p&gt;
&lt;p&gt;写持有锁时，其他写无法进行， 迁移无法进行&lt;/p&gt;
&lt;p&gt;迁移持有锁时，写无法进行&lt;/p&gt;
&lt;p&gt;实际操作时，可以进行迁移操作，迁移后更新status，但是并不读写新库&lt;/p&gt;
&lt;p&gt;观察服务与新老存储负载情况，再决定是否可采取该方案&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;当然，还是要看具体场景&lt;/p&gt;
&lt;p&gt;有些场景会有更简单的解决方案&lt;/p&gt;
</content>
    </item>
    
  </channel>
</rss>
